# Настройка плагина

## Основные настройки

Настройка плагина осуществляется через System Console → Plugins → Summary.

### Выбор LLM провайдера

**LLM Provider** - основная настройка, определяющая какой сервис будет использоваться для генерации резюме:

- `ollama` - для использования локальных моделей через Ollama
- `openai` - для использования OpenAI или совместимых API

### Настройки Ollama

При выборе провайдера `ollama` доступны следующие параметры:

| Параметр | Описание | По умолчанию |
|----------|----------|--------------|
| **Ollama URL** | Адрес сервера Ollama | `http://localhost:11434` |
| **Ollama Model** | Название модели для использования | `llama3.2` |
| **Ollama Timeout** | Таймаут запроса в секундах | `60` |

!!! tip "Рекомендуемые модели"
    - `llama3.2` - лучшее соотношение качества и скорости
    - `qwen2.5` - хорошее понимание русского языка
    - `mistral` - быстрая генерация, меньше требований к ресурсам

### Настройки OpenAI

При выборе провайдера `openai` доступны следующие параметры:

| Параметр | Описание | По умолчанию |
|----------|----------|--------------|
| **OpenAI API Key** | Ключ доступа к API | (пусто) |
| **OpenAI Model** | Название модели | `gpt-3.5-turbo` |
| **OpenAI Base URL** | Базовый URL API | `https://api.openai.com/v1` |
| **OpenAI Timeout** | Таймаут запроса в секундах | `30` |

!!! warning "Безопасность API ключа"
    API ключ хранится в зашифрованном виде в базе данных Mattermost. Убедитесь, что доступ к System Console имеют только доверенные администраторы.

## Настройки промптов

### Системный промпт

**System Prompt** - инструкция для модели о том, как создавать резюме:

```
Ты - ассистент для суммаризации сообщений в корпоративном мессенджере. 
Создай краткое и информативное резюме основных тем и решений из предоставленных сообщений.
Ответь на русском языке. Структурируй ответ с использованием маркеров или нумерации.
```

!!! note "Кастомизация промпта"
    Вы можете изменить системный промпт для адаптации под специфику вашей организации или предпочтения в стиле резюме.

### Языковые настройки

| Параметр | Описание | По умолчанию |
|----------|----------|--------------|
| **Language** | Язык для генерации резюме | `ru` |
| **Max Tokens** | Максимальное количество токенов в ответе | `500` |

## Настройки производительности

### Таймауты

Настройка таймаутов важна для стабильной работы плагина:

- **Короткие таймауты** (15-30 сек) - для быстрых API вроде OpenAI
- **Длинные таймауты** (60-120 сек) - для локальных моделей Ollama

### Ограничения

| Параметр | Описание | Значение |
|----------|----------|----------|
| **Max Messages** | Максимальное количество сообщений в треде для обработки | `50` |
| **Max Message Length** | Максимальная длина одного сообщения (символы) | `2000` |

## Расширенные настройки

### Кэширование

Для оптимизации производительности можно настроить кэширование результатов:

- **Enable Caching** - включить кэширование резюме
- **Cache TTL** - время жизни кэша в минутах (по умолчанию 60)

### Логирование

Для отладки и мониторинга:

- **Debug Mode** - включить подробное логирование
- **Log Requests** - логировать запросы к LLM провайдерам

## Конфигурация через переменные окружения

Для развертывания в Docker или Kubernetes можно использовать переменные окружения:

```bash
# Основные настройки
export PLUGIN_SUMMARY_LLM_PROVIDER=ollama
export PLUGIN_SUMMARY_OLLAMA_URL=http://ollama:11434
export PLUGIN_SUMMARY_OLLAMA_MODEL=llama3.2

# Или для OpenAI
export PLUGIN_SUMMARY_LLM_PROVIDER=openai
export PLUGIN_SUMMARY_OPENAI_API_KEY=sk-...
export PLUGIN_SUMMARY_OPENAI_MODEL=gpt-4
```

## Проверка конфигурации

После изменения настроек рекомендуется проверить работоспособность:

1. **Health Check** - в настройках плагина есть кнопка "Test Connection"
2. **Тестовое резюме** - создайте тестовый тред и выполните `/summary`
3. **Логи** - проверьте логи сервера на наличие ошибок

!!! success "Готово к работе"
    После успешной настройки плагин готов к использованию. Команда `/summary` будет доступна во всех каналах для пользователей с соответствующими правами.
